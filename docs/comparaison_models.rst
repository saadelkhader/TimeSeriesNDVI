###########################################################
Comparaison des Mod√®les : SARIMA vs. XGBoost vs. LSTM
###########################################################

Cette page pr√©sente une analyse comparative rigoureuse de trois approches diff√©rentes pour la pr√©diction de la s√©rie temporelle du NDVI :
1.  **SARIMA** : Un mod√®le statistique classique (univari√©).
2.  **XGBoost** : Un mod√®le de Machine Learning bas√© sur les arbres de d√©cision (multivari√©).
3.  **LSTM** : Un mod√®le de Deep Learning sp√©cialis√© dans les s√©quences (multivari√©).

L'objectif est d'√©valuer objectivement leur performance sur une p√©riode de test commune afin de s√©lectionner le mod√®le le plus pr√©cis et le plus fiable pour ce projet.

**************************************************
Phase 1 : M√©thodologie de Comparaison
**************************************************

Pour garantir une comparaison √©quitable, un protocole strict a √©t√© mis en place.

1.1. Pr√©paration Unifi√©e des Donn√©es
=====================================
Toutes les donn√©es ant√©rieures au **1er janvier 2024** sont utilis√©es pour l'entra√Ænement, et l'ann√©e **2024** compl√®te sert de p√©riode de test commune pour √©valuer les performances de chaque mod√®le sur des donn√©es qu'il n'a jamais vues.

.. admonition:: Diff√©rences Fondamentales dans la Pr√©paration
   :class: important

   * **SARIMA** : Ce mod√®le est **univari√©**, il n'utilise que l'historique de la variable NDVI elle-m√™me. Pour capturer la saisonnalit√© annuelle, les donn√©es sont agr√©g√©es √† une fr√©quence **hebdomadaire**.
   * **XGBoost et LSTM** : Ces mod√®les sont **multivari√©s**. Ils utilisent non seulement l'historique du NDVI (via des "lags"), mais aussi des **variables exog√®nes** (temp√©rature, humidit√©, pr√©cipitations) et des caract√©ristiques temporelles (mois, jour de l'ann√©e) pour enrichir leur pr√©diction. Ils travaillent sur les donn√©es **journali√®res**.

.. code-block:: python

   # --- √âTAPE 1: CHARGEMENT ET PR√âPARATION UNIFI√âE DES DONN√âES ---
   
   # Nettoyage robuste des donn√©es fusionn√©es
   df_final = pd.read_csv("data_fusionner_netoyeer.csv")
   df_final['date'] = pd.to_datetime(df_final['date'])
   df_final = df_final.set_index('date').sort_index()
   # ... (code de nettoyage) ...
   
   # D√©finition de la p√©riode de test commune
   split_date = '2024-01-01'
   
   # Pr√©paration pour SARIMA (hebdomadaire, univari√©)
   df_weekly = df_final['NDVI'].resample('W').mean().interpolate().bfill()
   train_sarima = df_weekly[df_weekly.index < split_date]
   test_sarima = df_weekly[df_weekly.index >= split_date]
   
   # Pr√©paration pour XGBoost et LSTM (journalier, multivari√©)
   df_model = df_final.copy()
   # ... (cr√©ation des caract√©ristiques : lags, mois, jour_annee) ...
   X_train, X_test = X[X.index < split_date], X[X.index >= split_date]
   y_train, y_test = y[y.index < split_date], y[y.index >= split_date]


1.2. M√©triques d'√âvaluation
============================
Deux m√©triques standards sont utilis√©es pour mesurer l'erreur de pr√©diction :
* **RMSE (Root Mean Squared Error)** : L'erreur quadratique moyenne. Elle p√©nalise davantage les grosses erreurs.
* **MAE (Mean Absolute Error)** : L'erreur absolue moyenne. Elle est plus facile √† interpr√©ter.

Pour les deux m√©triques, **un score plus bas indique un meilleur mod√®le**.

**************************************************
Phase 2 : Entra√Ænement et Pr√©dictions
**************************************************

Les trois mod√®les sont entra√Æn√©s sur la m√™me p√©riode historique. Ensuite, ils g√©n√®rent des pr√©dictions pour l'ann√©e de test (2024).

.. code-block:: python

   # --- √âTAPE 2: ENTRA√éNEMENT DES TROIS MOD√àLES ---
   
   # Mod√®le 1: SARIMA
   model_sarima = sm.tsa.SARIMAX(train_sarima, order=(0, 1, 1), seasonal_order=(0, 1, 1, 52)).fit(disp=False)
   
   # Mod√®le 2: XGBoost
   model_xgb = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, random_state=42)
   model_xgb.fit(X_train, y_train)
   
   # Mod√®le 3: LSTM
   # ... (Normalisation et reformatage des donn√©es pour LSTM) ...
   model_lstm = Sequential(...)
   model_lstm.compile(...)
   model_lstm.fit(...)

.. code-block:: python

   # --- √âTAPE 3: G√âN√âRATION ET ALIGNEMENT DES PR√âDICTIONS ---

   # G√©n√©rer les pr√©dictions pour chaque mod√®le
   pred_sarima = model_sarima.get_forecast(steps=len(test_sarima)).predicted_mean
   pred_xgb_daily = pd.Series(model_xgb.predict(X_test), index=X_test.index)
   # ... (pr√©dictions LSTM) ...

   # Cr√©ation du DataFrame de r√©sultats align√©s par semaine pour la comparaison
   df_results = pd.DataFrame({'NDVI_Reel': test_sarima})
   df_results['SARIMA_pred'] = pred_sarima
   df_results['XGBoost_pred'] = pred_xgb_daily.resample('W').mean()
   df_results['LSTM_pred'] = pred_lstm_daily.resample('W').mean()
   df_results = df_results.dropna()

**************************************************
Phase 3 : Analyse Comparative des R√©sultats
**************************************************

3.1. Comparaison Quantitative des Erreurs
==========================================

Les m√©triques RMSE et MAE sont calcul√©es pour chaque mod√®le sur la p√©riode de test.

.. admonition:: Tableau des M√©triques
   :class: note

   .. list-table::
      :header-rows: 1

      * - Mod√®le
        - RMSE
        - MAE
      * - SARIMA
        - 0.027777
        - 0.020787
      * - XGBoost
        - **0.028302**
        - *0.0204408**
      * - LSTM
        - 0.031210
        - 0.024639

.. image:: _static/votre_image_bar_chart_erreurs.png
   :alt: Comparaison des erreurs des mod√®les
   :align: center
   :width: 80%

   *Figure 1 : Comparaison des scores d'erreur. Les mod√®les de Machine Learning (XGBoost, LSTM) sont nettement plus performants que le mod√®le statistique SARIMA.*

3.2. Comparaison Visuelle des Pr√©dictions
==========================================
La comparaison des courbes de pr√©diction avec la r√©alit√© permet une √©valuation qualitative.

.. image:: _static/votre_image_comparaison_courbes.png
   :alt: Comparaison des courbes de pr√©dictions
   :align: center
   :width: 90%

   *Figure 2 : Pr√©dictions vs R√©alit√© (2024). Les courbes de XGBoost et LSTM (orange, vert) suivent de tr√®s pr√®s la courbe r√©elle (noir), tandis que celle de SARIMA (bleu) est d√©cal√©e et moins pr√©cise.*

3.3. Analyse de la Distribution des Erreurs
============================================
Le boxplot des erreurs (R√©el - Pr√©dit) montre la dispersion et le biais de chaque mod√®le.

.. image:: _static/votre_image_boxplot_erreurs.png
   :alt: Distribution des erreurs par mod√®le
   :align: center
   :width: 80%

   *Figure 3 : Les bo√Ætes pour XGBoost et LSTM sont petites et centr√©es sur z√©ro, indiquant des erreurs faibles et non biais√©es. La bo√Æte de SARIMA est large et au-dessus de z√©ro, montrant une tendance √† la sous-estimation.*

**************************************************
Phase 4 : Conclusion et Choix du Mod√®le
**************************************************

.. admonition:: üèÜ Le Gagnant : XGBoost
   :class: important

   Bien que les performances de **XGBoost** et **LSTM** soient tr√®s similaires et excellentes, **XGBoost est choisi comme le meilleur mod√®le** pour ce projet pour les raisons suivantes :

   1.  **Rapidit√© et Simplicit√©** : Il est beaucoup plus rapide √† entra√Æner que le LSTM, qui n√©cessite une pr√©paration des donn√©es plus complexe (s√©quences, normalisation).
   2.  **Robustesse** : Il est g√©n√©ralement plus simple √† optimiser et moins sujet √† des probl√®mes d'entra√Ænement complexes.
   3.  **Interpr√©tabilit√©** : Il est plus facile d'extraire l'importance des caract√©ristiques (feature importance) d'un mod√®le XGBoost pour comprendre quels facteurs (climat, lags) influencent le plus la pr√©diction.

   Le mod√®le **SARIMA**, bien qu'utile pour des s√©ries temporelles simples, a montr√© ses limites ici. Son incapacit√© √† int√©grer des variables externes comme la m√©t√©o l'a rendu significativement moins pr√©cis que les mod√®les de Machine Learning.
